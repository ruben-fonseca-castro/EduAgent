# LLM Provider: anthropic | openai | ollama
LLM_PROVIDER=anthropic
LLM_MODEL=claude-sonnet-4-6
LLM_TEMPERATURE=0.7

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI (if using openai provider)
OPENAI_API_KEY=sk-...
# For OpenAI-compatible endpoints (e.g. Oracle Cloud Gen AI):
# OPENAI_API_BASE=https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/...

# Ollama (if using ollama provider)
OLLAMA_BASE_URL=http://localhost:11434

# Oracle Cloud Generative AI (if using oci provider)
# LLM_PROVIDER=oci
# LLM_MODEL=meta.llama-3.3-70b-instruct
# OCI_COMPARTMENT_ID=ocid1.compartment.oc1..aaaa...
# OCI_SERVICE_ENDPOINT=https://inference.generativeai.us-chicago-1.oci.oraclecloud.com
# OCI_CONFIG_PROFILE=DEFAULT

# Paths
DATA_DIR=./data
CHROMA_DB_PATH=./data/chroma_db
LESSONS_DIR=./data/generated_lessons
STUDENT_CONTEXT_DIR=./data/student_context
MCP_SERVER_PATH=./backend/mcp_servers/python_executor.py

# App
APP_HOST=0.0.0.0
APP_PORT=8000
